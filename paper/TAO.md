# TAO: A Large-Scale Benchmark for Tracking Any Object
https://arxiv.org/pdf/2005.10356
# Abstract
- 提出Tracking Any Object (TAO)数据集
  - 不同环境下的2907个高分辨率视频，平均长度为1分钟
  - 833个类别的词汇表：要求标注者标记视频中任意点移动的目标，并事后为它们命名
  - 为了确保标注的可扩展性，本文采用了一种联合方法，该方法将手动的工作重点放在视频中相关目标（例如移动的目标）的track的标注上
- 在开放世界的大词汇量跟踪上，评估了最先进的跟踪器
  - 现有的SOT、MOT跟踪器应用这种场景会有困难，特别是对于尾部不常见的目标类别
  - 虽然跟踪器对于最常探索的人群来说效果明显更好，但在不同场景（例如频繁遮挡或相机运动）中跟踪人员仍然具有挑战性
  - detection-based的MOT跟踪器比user-initialized的跟踪器更具有竞争力

# Introduction
现有的检测数据集规模和种类都很大，相反地，MOT数据集很小，如表1所示，从图1可知MOT数据集的类别主要是人和车辆
<center><img src=../images/image-32.png style="zoom:50%"></center>
<center><img src=../images/image-33.png style="zoom:50%"></center>

图2为TAO的代表性帧
<center><img src=../images/image-39.png style="zoom:50%"></center>

存在的挑战：
- 如何选择大量多样化的、长的、高质量的视频
- 如何定义一组涵盖所有可能对感兴趣去跟踪的目标的类别
  - 常规的方法：大多数数据集是自上而下方法构建，由决策者首先选择与任务相关的类别集合，然后专门收集这类视频，很容易引入决策者偏见
  - 本文的方法：
    - 自下而上、开放世界方法构建，首先要求标注者标记所有自行移动或被人移动的目标，然后为标记的目标命名，这样产生的词汇表不仅更大，而且词汇表的质量会更高
    - 为促进目标检测器的训练，鼓励标注这使用LVIS数据集中存在的类别，如果找不到，可以提供自由格式的名称
- 如何以实际成本标注这些类别的track

# Dataset design
## 标注的粒度
每秒1帧的速度标记track，理由：基于对OxUvA论文的观察，即密集帧标记不会改变方法的相对性能

# Metrics

分别计算每个类别的指标，然后跨类别将它们组合起来：  
- 对于 MOTA 和 ID-F1 等指标，我们报告跨类别的平均值  
- 对于技术的，包括 MT（大部分跟踪）、ML（大部分丢失）、FP（假阳性）、FN（假阴性）和 ID Sw（身份切换），我们报告跨类别的总和  
在附录C.2有对不同跟踪模型调参的方法，基于MAP调参